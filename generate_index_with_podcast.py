#!/usr/bin/env python3
# coding=utf-8
"""
ä¸º GitHub Pages ç”Ÿæˆå¸¦æ’­å®¢çš„ index.html
- ç²¾ç®€ç‰ˆï¼šæ¯ä¸ªä¸»é¢˜å–10æ¡æ–°é—»
- ç”Ÿæˆæ’­å®¢éŸ³é¢‘
- åœ¨ index.html ä¸­é›†æˆæ’­æ”¾å™¨
"""

import os
import sys
from pathlib import Path
from datetime import datetime
import pytz
import requests
from typing import Optional
import asyncio


def get_beijing_time():
    """è·å–åŒ—äº¬æ—¶é—´"""
    return datetime.now(pytz.timezone("Asia/Shanghai"))


def format_date_folder():
    """æ ¼å¼åŒ–æ—¥æœŸæ–‡ä»¶å¤¹"""
    return get_beijing_time().strftime("%Yå¹´%mæœˆ%dæ—¥")


def ensure_directory_exists(directory: str):
    """ç¡®ä¿ç›®å½•å­˜åœ¨"""
    Path(directory).mkdir(parents=True, exist_ok=True)


def read_latest_news_for_summary() -> Optional[str]:
    """è¯»å–æœ€æ–°çš„æ–°é—»æ–‡ä»¶ç”¨äºç”Ÿæˆæ‘˜è¦"""
    date_folder = format_date_folder()
    txt_dir = Path("output") / date_folder / "txt"

    if not txt_dir.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {txt_dir}")
        return None

    txt_files = sorted([f for f in txt_dir.iterdir() if f.suffix == ".txt"])
    if not txt_files:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°txtæ–‡ä»¶")
        return None

    latest_file = txt_files[-1]
    print(f"âœ… è¯»å–æ–°é—»æ–‡ä»¶: {latest_file.name}")

    with open(latest_file, "r", encoding="utf-8") as f:
        content = f.read()

    return content


def parse_and_simplify_news(news_content: str, max_items_per_platform: int = 10) -> list:
    """è§£æå¹¶ç®€åŒ–æ–°é—»å†…å®¹"""
    lines = news_content.strip().split("\n")

    news_data = []
    current_platform = ""
    current_platform_news = []

    for line in lines:
        line = line.strip()
        if not line or "==== ä»¥ä¸‹IDè¯·æ±‚å¤±è´¥ ====" in line:
            continue

        # æ£€æµ‹å¹³å°åç§°è¡Œ
        if not line[0].isdigit() and ("|" in line or "[" not in line):
            # ä¿å­˜ä¸Šä¸€ä¸ªå¹³å°çš„æ•°æ®
            if current_platform_news and current_platform:
                news_data.append({
                    "platform": current_platform,
                    "items": current_platform_news[:max_items_per_platform]
                })
                current_platform_news = []

            # è§£ææ–°å¹³å°
            if "|" in line:
                parts = line.split("|")
                current_platform = parts[1].strip() if len(parts) > 1 else parts[0].strip()
            else:
                current_platform = line

        elif line[0].isdigit() and ". " in line:
            # æ–°é—»æ¡ç›®è¡Œ
            title = line.split(". ", 1)[1]
            # ç§»é™¤URLé“¾æ¥éƒ¨åˆ†
            if "[URL:" in title:
                title = title.split("[URL:")[0].strip()
            if "[MOBILE:" in title:
                title = title.split("[MOBILE:")[0].strip()

            current_platform_news.append(title)

    # å¤„ç†æœ€åä¸€ä¸ªå¹³å°
    if current_platform_news and current_platform:
        news_data.append({
            "platform": current_platform,
            "items": current_platform_news[:max_items_per_platform]
        })

    return news_data


def generate_podcast_script_with_ai(news_data: list, api_key: str) -> Optional[str]:
    """ä½¿ç”¨ OpenRouter qwen-2.5-72b-instruct ç”Ÿæˆæ’­å®¢è„šæœ¬"""

    # æ„å»ºæç¤ºè¯, å¹³å°éƒ½å–ï¼Œå½“ç„¶ç”¨æˆ·å¯ä»¥è°ƒæ•´ news_data çš„æ•°æ®æ¥å‡å°‘å†…å®¹
    news_summary = ""
    for platform_data in news_data:
        platform = platform_data["platform"]
        items = platform_data["items"]
        news_summary += f"\nã€{platform}ã€‘\n"
        for i, item in enumerate(items, 1):
            news_summary += f"{i}. {item}\n"

    prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ’­å®¢ä¸»æ’­ï¼Œåå­—å«å°ä¸¥æ–°é—»è”æ’­ï¼Œéœ€è¦å°†ä»¥ä¸‹æ–°é—»çƒ­ç‚¹æ”¹ç¼–æˆä¸€ç¯‡è‡ªç„¶ã€æµç•…çš„æ’­å®¢ç¨¿ã€‚

è¦æ±‚ï¼š
1. è¯­è¨€é£æ ¼ä¸“ä¸šï¼Œåƒåœ¨å¬æ–°é—»è”æ’­
2. æ¯æ¡æ–°é—»è¦ç®€æ´ç²¾ç‚¼ï¼Œçªå‡ºå…³é”®ä¿¡æ¯
3. å¹³å°ä¹‹é—´çš„è¿‡æ¸¡è¦è‡ªç„¶
4. å¼€å¤´è¦æœ‰æ¬¢è¿è¯­ï¼Œç»“å°¾è¦æœ‰æ€»ç»“
5. æ€»æ—¶é•¿æ§åˆ¶åœ¨5-10åˆ†é’Ÿï¼ˆçº¦1200-2400å­—ï¼‰
6. é¿å…ä½¿ç”¨è¿‡åº¦ä¸“ä¸šçš„æœ¯è¯­ç¡®ä¿æ’­å®¢å†…å®¹å¯¹ä¸€èˆ¬å¬ä¼—ä¹Ÿæœ‰ä»·å€¼


æ–°é—»å†…å®¹ï¼š
{news_summary}

è¯·ç›´æ¥è¾“å‡ºæ’­å®¢ç¨¿ï¼Œä¸è¦æœ‰å…¶ä»–è¯´æ˜æ–‡å­—ï¼Œä¸è¦ç”¨Markdownæ ¼å¼ä»¥ä¿è¯ttså‹å¥½"""

    print("ğŸ¤– æ­£åœ¨è°ƒç”¨ qwen-2.5-72b-instruct ç”Ÿæˆæ’­å®¢è„šæœ¬...")

    try:
        response = requests.post(
            url="https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            },
            json={
                "model": "qwen/qwen-2.5-72b-instruct",  # ä½¿ç”¨ Qwen 2.5 72B
                "messages": [{"role": "user", "content": prompt}],
                "temperature": 0.8,  # æé«˜æ¸©åº¦è®©å†…å®¹æ›´æœ‰åˆ›æ„
                "max_tokens": 3500,  # å¢åŠ  token é™åˆ¶ä»¥æ”¯æŒæ›´é•¿å†…å®¹
            },
            timeout=90  # å¢åŠ è¶…æ—¶æ—¶é—´
        )

        if response.status_code == 200:
            result = response.json()
            script = result["choices"][0]["message"]["content"]
            print("âœ… AI è„šæœ¬ç”ŸæˆæˆåŠŸ")
            return script
        else:
            print(f"âŒ API è°ƒç”¨å¤±è´¥: {response.status_code}")
            return None

    except Exception as e:
        print(f"âŒ ç”Ÿæˆè„šæœ¬æ—¶å‡ºé”™: {e}")
        return None


def generate_audio_with_edge_tts(script: str, output_path: Path) -> bool:
    """ä½¿ç”¨ Edge TTS ç”ŸæˆéŸ³é¢‘"""
    try:
        print("ğŸ™ï¸  ä½¿ç”¨ Edge TTS ç”ŸæˆéŸ³é¢‘...")

        import edge_tts

        async def generate():
            communicate = edge_tts.Communicate(script, "zh-CN-YunyangNeural")
            await communicate.save(str(output_path))

        asyncio.run(generate())
        print(f"âœ… éŸ³é¢‘ç”ŸæˆæˆåŠŸ: {output_path}")
        return True

    except ImportError:
        print("âš ï¸  edge-tts æœªå®‰è£…ï¼Œè·³è¿‡éŸ³é¢‘ç”Ÿæˆ")
        return False
    except Exception as e:
        print(f"âŒ ç”ŸæˆéŸ³é¢‘æ—¶å‡ºé”™: {e}")
        return False


def generate_index_html_with_podcast(news_data: list, audio_filename: str):
    """ç”Ÿæˆå¸¦æ’­å®¢çš„ index.html"""
    from main import render_html_content, prepare_report_data

    # å°†ç®€åŒ–çš„æ–°é—»æ•°æ®è½¬æ¢ä¸º stats æ ¼å¼
    stats = []
    for platform_data in news_data:
        for idx, title in enumerate(platform_data["items"]):
            stats.append({
                'word': title[:20],  # å–æ ‡é¢˜å‰20å­—ä½œä¸ºå…³é”®è¯
                'count': 1,
                'position': idx,
                'percentage': 100.0,
                'titles': [{
                    'title': title,
                    'source_name': platform_data["platform"],
                    'first_time': get_beijing_time().strftime("%Hæ—¶%Måˆ†"),
                    'last_time': get_beijing_time().strftime("%Hæ—¶%Måˆ†"),
                    'time_display': get_beijing_time().strftime("%Hæ—¶%Måˆ†"),
                    'count': 1,
                    'ranks': [idx + 1],
                    'rank_threshold': 10,
                    'url': '',
                    'mobileUrl': '',
                    'is_new': False
                }]
            })

    total_titles = sum(len(p["items"]) for p in news_data)

    report_data = prepare_report_data(stats, None, None, None, "daily")

    # è®¾ç½®éŸ³é¢‘æ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äº index.htmlï¼‰
    date_folder = format_date_folder()
    audio_file = f"output/{date_folder}/audio/{audio_filename}"

    html_content = render_html_content(
        report_data,
        total_titles,
        is_daily_summary=False,  # æ”¹ä¸º Falseï¼Œè¿™æ ·ä¼šæ˜¾ç¤ºæ’­æ”¾å™¨
        mode="daily",
        update_info=None,
        audio_file=audio_file
    )

    # å†™å…¥ index.html
    with open("index.html", "w", encoding="utf-8") as f:
        f.write(html_content)

    print(f"âœ… index.html å·²ç”Ÿæˆï¼ˆåŒ…å«éŸ³é¢‘æ’­æ”¾å™¨ï¼‰")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ™ï¸  ç”Ÿæˆå¸¦æ’­å®¢çš„ index.html for GitHub Pages")
    print("=" * 60)

    # 1. æ£€æŸ¥ API Key
    api_key = os.environ.get("OPENROUTER_API_KEY", "")
    if not api_key:
        print("âŒ é”™è¯¯: æœªæ‰¾åˆ° OPENROUTER_API_KEY ç¯å¢ƒå˜é‡")
        return 1

    # 2. è¯»å–æœ€æ–°æ–°é—»
    news_content = read_latest_news_for_summary()
    if not news_content:
        print("âŒ æ— æ³•è¯»å–æ–°é—»å†…å®¹")
        return 1

    # 3. è§£æå¹¶ç®€åŒ–æ–°é—»ï¼ˆæ¯ä¸ªå¹³å°å–10æ¡ï¼‰
    print("ğŸ“ è§£ææ–°é—»å†…å®¹ï¼ˆæ¯ä¸ªå¹³å°å–10æ¡ï¼‰...")
    news_data = parse_and_simplify_news(news_content, max_items_per_platform=10)
    print(f"âœ… è§£æåˆ° {len(news_data)} ä¸ªå¹³å°çš„æ–°é—»")

    # 4. å‡†å¤‡éŸ³é¢‘æ–‡ä»¶è·¯å¾„
    date_folder = format_date_folder()
    audio_dir = Path("output") / date_folder / "audio"
    ensure_directory_exists(str(audio_dir))

    audio_filename = "podcast.mp3"  # å›ºå®šæ–‡ä»¶å
    audio_path = audio_dir / audio_filename
    script_path = audio_dir / "podcast_script.txt"

    # 5. ç”Ÿæˆæ’­å®¢è„šæœ¬
    script = generate_podcast_script_with_ai(news_data, api_key)
    if not script:
        print("âŒ è„šæœ¬ç”Ÿæˆå¤±è´¥")
        return 1

    # ä¿å­˜è„šæœ¬
    with open(script_path, "w", encoding="utf-8") as f:
        f.write(script)
    print(f"âœ… æ’­å®¢è„šæœ¬å·²ä¿å­˜: {script_path}")

    # 6. ç”ŸæˆéŸ³é¢‘
    audio_generated = generate_audio_with_edge_tts(script, audio_path)

    if not audio_generated:
        print("âš ï¸  éŸ³é¢‘ç”Ÿæˆå¤±è´¥ï¼Œä½†ä¼šç»§ç»­ç”Ÿæˆ HTML")
        # åˆ›å»ºä¸€ä¸ªç©ºæ–‡ä»¶å ä½
        audio_path.touch()

    # 7. ç”Ÿæˆ index.html
    print("ğŸ“„ ç”Ÿæˆ index.html...")
    generate_index_html_with_podcast(news_data, audio_filename)

    # 8. å®Œæˆ
    print("\n" + "=" * 60)
    print("âœ… å®Œæˆï¼")
    print("=" * 60)
    print(f"ğŸ“ æ’­å®¢è„šæœ¬: {script_path}")
    if audio_path.exists():
        print(f"ğŸµ éŸ³é¢‘æ–‡ä»¶: {audio_path} ({audio_path.stat().st_size / 1024:.1f} KB)")
    print(f"ğŸ“„ é¦–é¡µ: index.html")
    print("\nğŸ’¡ index.html å·²åŒ…å«éŸ³é¢‘æ’­æ”¾å™¨ï¼Œå¯ç›´æ¥éƒ¨ç½²åˆ° GitHub Pages")

    return 0


if __name__ == "__main__":
    sys.exit(main())
